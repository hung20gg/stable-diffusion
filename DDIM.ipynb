{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will implement DDIM, alternative sampling method for Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: The majority of code in this notebook are similar to [DDPM](./DDPM.ipynb). The only different is on sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from torchvision.datasets.mnist import MNIST, FashionMNIST\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "no_train = False\n",
    "fashion = True\n",
    "batch_size = 256\n",
    "n_epochs = 20\n",
    "lr = 0.0001\n",
    "store_path = \"ddpm_fashion.pt\" if fashion else \"ddpm_mnist.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title=\"\"):\n",
    "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
    "\n",
    "    # Converting images to CPU numpy arrays\n",
    "    if type(images) is torch.Tensor:\n",
    "        images = images.detach().cpu().numpy()\n",
    "\n",
    "    # Defining number of rows and columns\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    rows = int(len(images) ** (1 / 2))\n",
    "    cols = round(len(images) / rows)\n",
    "\n",
    "    # Populating figure with sub-plots\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            fig.add_subplot(rows, cols, idx + 1)\n",
    "\n",
    "            if idx < len(images):\n",
    "                plt.imshow(images[idx][0], cmap=\"gray\")\n",
    "                idx += 1\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "\n",
    "    # Showing the figure\n",
    "    plt.show()\n",
    "    \n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: (x - 0.5) * 2)\n",
    "    ]\n",
    ")\n",
    "ds_fn = FashionMNIST if fashion else MNIST\n",
    "dataset = ds_fn(\"./datasets\", download=True, train=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "  def __init__(self, network, n_steps=200, min_b=10**-4, max_b= 0.02,device=None, image_chw=(1,28,28)):\n",
    "    super().__init__()\n",
    "    self.n_steps = n_steps\n",
    "    self.device = device\n",
    "    self.image_chw = image_chw\n",
    "    self.network = network.to(device)\n",
    "    self.beta = torch.linspace(min_b,max_b,n_steps).to(device)\n",
    "    self.alpha= 1 - self.beta\n",
    "    self.alpha_bar=torch.tensor([torch.prod(self.alpha[:i+1]) for i in range(len(self.alpha))]).to(device)\n",
    "\n",
    "  def forward(self,x0,t,eta=None): # forward process on DDPM\n",
    "    n,c,h,w = x0.shape\n",
    "    a_bar = self.alpha_bar[t]\n",
    "    if eta is None:\n",
    "      eta = torch.randn(n,c,h,w).to(self.device)\n",
    "\n",
    "    noise = a_bar.sqrt().reshape(n,1,1,1)*x0 + (1-a_bar).sqrt().reshape(n,1,1,1)*eta\n",
    "    return noise\n",
    "\n",
    "  def backward(self,x,t): # reverse process on DDPM\n",
    "    return self.network(x,t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "  def __init__(self,shape, in_c, out_c, kernel_size=3, stride=1,padding=1, activation=None, normalize= True):\n",
    "    super().__init__()\n",
    "    self.ln= nn.LayerNorm(shape)\n",
    "    self.conv1 = nn.Conv2d(in_c,out_c,kernel_size,stride,padding)\n",
    "    self.conv2 = nn.Conv2d(out_c,out_c,kernel_size,stride,padding)\n",
    "    self.activation = nn.SiLU() if activation is None else activation\n",
    "    self.normalize = normalize\n",
    "\n",
    "  def forward(self,x):\n",
    "    out = self.ln(x) if self.normalize else x\n",
    "    out = self.activation(self.conv1(out))\n",
    "    out = self.activation(self.conv2(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "  def __init__(self, n_steps=1000, time_emb_dim=100):\n",
    "    super().__init__()\n",
    "    self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
    "    self.time_embed.weight.data = self.sinusoidal_embedding(n_steps,time_emb_dim)\n",
    "    self.time_embed.requires_grad_(False)\n",
    "\n",
    "    # Left U\n",
    "    self.te1 = self._make_te(time_emb_dim, 1)\n",
    "    self.b1 = nn.Sequential(\n",
    "        Block((1, 28, 28), 1, 10),\n",
    "        Block((10, 28, 28), 10, 10),\n",
    "        Block((10, 28, 28), 10, 10)\n",
    "    )\n",
    "    self.down1 = nn.Conv2d(10, 10, 4, 2, 1)\n",
    "\n",
    "    self.te2 = self._make_te(time_emb_dim, 10)\n",
    "    self.b2 = nn.Sequential(\n",
    "        Block((10, 14, 14), 10, 20),\n",
    "        Block((20, 14, 14), 20, 20),\n",
    "        Block((20, 14, 14), 20, 20)\n",
    "    )\n",
    "    self.down2 = nn.Conv2d(20, 20, 4, 2, 1)\n",
    "    self.te3 = self._make_te(time_emb_dim, 20)\n",
    "    self.b3 = nn.Sequential(\n",
    "            Block((20, 7, 7), 20, 40),\n",
    "            Block((40, 7, 7), 40, 40),\n",
    "            Block((40, 7, 7), 40, 40)\n",
    "        )\n",
    "    self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(40, 40, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(40, 40, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "    # Middle U\n",
    "\n",
    "    self.te_mid = self._make_te(time_emb_dim, 40)\n",
    "    self.b_mid = nn.Sequential(\n",
    "            Block((40, 3, 3), 40, 20),\n",
    "            Block((20, 3, 3), 20, 20),\n",
    "            Block((20, 3, 3), 20, 40)\n",
    "        )\n",
    "\n",
    "    # Second half\n",
    "    self.up1 = nn.Sequential(\n",
    "        nn.ConvTranspose2d(40, 40, 4, 2, 1),\n",
    "        nn.SiLU(),\n",
    "        nn.ConvTranspose2d(40, 40, 2, 1)\n",
    "    )\n",
    "\n",
    "    self.te4 = self._make_te(time_emb_dim, 80)\n",
    "    self.b4 = nn.Sequential(\n",
    "        Block((80, 7, 7), 80, 40),\n",
    "        Block((40, 7, 7), 40, 20),\n",
    "        Block((20, 7, 7), 20, 20)\n",
    "    )\n",
    "\n",
    "    self.up2 = nn.ConvTranspose2d(20, 20, 4, 2, 1)\n",
    "    self.te5 = self._make_te(time_emb_dim, 40)\n",
    "    self.b5 = nn.Sequential(\n",
    "        Block((40, 14, 14), 40, 20),\n",
    "        Block((20, 14, 14), 20, 10),\n",
    "        Block((10, 14, 14), 10, 10)\n",
    "    )\n",
    "\n",
    "    self.up3 = nn.ConvTranspose2d(10, 10, 4, 2, 1)\n",
    "    self.te_out = self._make_te(time_emb_dim, 20)\n",
    "    self.b_out = nn.Sequential(\n",
    "        Block((20, 28, 28), 20, 10),\n",
    "        Block((10, 28, 28), 10, 10),\n",
    "        Block((10, 28, 28), 10, 10, normalize=False)\n",
    "    )\n",
    "\n",
    "    self.conv_out = nn.Conv2d(10, 1, 3, 1, 1)\n",
    "\n",
    "  def forward(self, x, t):\n",
    "    t = self.time_embed(t)\n",
    "    n = len(x)\n",
    "    out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))\n",
    "    out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))\n",
    "    out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))  # (N, 40, 7, 7)\n",
    "\n",
    "    out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))  # (N, 40, 3, 3)\n",
    "\n",
    "    out4 = torch.cat((out3, self.up1(out_mid)), dim=1)  # (N, 80, 7, 7)\n",
    "    out4 = self.b4(out4 + self.te4(t).reshape(n, -1, 1, 1))  # (N, 20, 7, 7)\n",
    "\n",
    "    out5 = torch.cat((out2, self.up2(out4)), dim=1)  # (N, 40, 14, 14)\n",
    "    out5 = self.b5(out5 + self.te5(t).reshape(n, -1, 1, 1))  # (N, 10, 14, 14)\n",
    "\n",
    "    out = torch.cat((out1, self.up3(out5)), dim=1)  # (N, 20, 28, 28)\n",
    "    out = self.b_out(out + self.te_out(t).reshape(n, -1, 1, 1))  # (N, 1, 28, 28)\n",
    "\n",
    "    out = self.conv_out(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "  @staticmethod\n",
    "  def sinusoidal_embedding(n,d):\n",
    "\n",
    "    embedding = torch.zeros(n,d)\n",
    "    wk = torch.tensor([1/10000 ** (2*j/d) for j in range(d)])\n",
    "    wk = wk.reshape((1,d))\n",
    "\n",
    "    t = torch.arange(n).reshape((n,1))\n",
    "    embedding[:,::2]  = torch.sin(t * wk[:,::2])\n",
    "    embedding[:,1::2] = torch.cos(t * wk[:,::2])\n",
    "\n",
    "    return embedding\n",
    "\n",
    "  def _make_te(self, dim_in, dim_out):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim_in, dim_out),\n",
    "        nn.SiLU(),\n",
    "        nn.Linear(dim_out, dim_out)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDIM \n",
    "This is DDIM Sampling method.\n",
    "\n",
    "Instead of sampling for $x_t$ for every $t$, **DDIM** only sample a subsample of $t$, such as: $t_0,t_3,t_6,t_9,..$. This helps reduce the computing speed in sampling method, help speed up the generating process significantly.\n",
    "\n",
    "The formular for DDIM sampling:\n",
    "\n",
    "$$\n",
    " x_{\\tau_{i-1}} = \\sqrt{\\alpha_{\\tau_{i-1}}}\\Bigg(\n",
    "            \\frac{x_{\\tau_i} - \\sqrt{1 - \\alpha_{\\tau_i}}\\epsilon_\\theta(x_{\\tau_i})}{\\sqrt{\\alpha_{\\tau_i}}}\n",
    "            \\Bigg) \\\n",
    "            + \\sqrt{1 - \\alpha_{\\tau_{i- 1}} - \\sigma_{\\tau_i}^2} \\cdot \\epsilon_\\theta(x_{\\tau_i}) \\\n",
    "            + \\sigma_{\\tau_i} \\epsilon_{\\tau_i}\n",
    "$$\n",
    "\n",
    "where $\\epsilon_{\\tau_i}$ is random noise,\n",
    "    $\\tau$ is a subsequence of $[1,2,\\dots,T]$ of length $S$, and:\n",
    "$$\\sigma_{\\tau_i} =\n",
    "    \\eta \\sqrt{\\frac{1 - \\alpha_{\\tau_{i-1}}}{1 - \\alpha_{\\tau_i}}}\n",
    "    \\sqrt{1 - \\frac{\\alpha_{\\tau_i}}{\\alpha_{\\tau_{i-1}}}}$$\n",
    "\n",
    "If $\\eta =1$, then the above sampling process becomes a DDPM sampling process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(ddpm, n_sample=16,device=None, c=1, h=28, w=28, jump = 10, ddim_eta = 1.):\n",
    "\n",
    "  with torch.no_grad():\n",
    "    if device is None:\n",
    "      device = ddpm.device\n",
    "    x = torch.randn(n_sample,c,h,w).to(device)\n",
    "\n",
    "    steps = ddpm.n_steps\n",
    "    alpha_bar = ddpm.alpha_bar\n",
    "    time_steps = torch.arrange(0,steps,jump).to(device) + 1\n",
    "    ddim_alpha = alpha_bar[time_steps].clone()\n",
    "    ddim_alpha_prev = torch.cat([alpha_bar[0:1], alpha_bar[time_steps[:-1]]])\n",
    "    ddim_sigma = (ddim_eta *\n",
    "                               ((1 - ddim_alpha_prev) / (1 - ddim_alpha) *\n",
    "                                (1 - ddim_alpha / ddim_alpha_prev)) ** .5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, step in enumerate(np.flip(time_steps)):\n",
    "      index = len(time_steps)-i-1\n",
    "      \n",
    "      ts = x.new_full((n_sample,1),step,dtypes=torch.long)\n",
    "\n",
    "      e_t = ddpm.backward(x,ts)\n",
    "      \n",
    "      alpha = ddim_alpha[index]\n",
    "      alpha_prev = ddim_alpha_prev[index]\n",
    "      \n",
    "      sigma = ddim_sigma[index]\n",
    "      \n",
    "      pred_x0 = (x - (1 - alpha).sqrt() * e_t)/alpha.sqrt()\n",
    "      \n",
    "      dir_xt = (1. - alpha_prev-sigma**2).sqrt() * e_t\n",
    "      \n",
    "      noise = torch.randn_like(x)\n",
    "      \n",
    "      x = alpha_prev.sqrt() * pred_x0 + dir_xt + sigma * noise\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(ddpm, loader, optim, device, n_epochs=20, display=False):\n",
    "  mse = nn.MSELoss()\n",
    "  n_steps = ddpm.n_steps\n",
    "  for epoch in range(n_epochs//10):\n",
    "    epoch_loss = 0.0\n",
    "    ddpm.network.train()\n",
    "    for i in tqdm(range(epoch*10, (epoch+1)*10), desc=f\"Epoch {epoch*10} to {(epoch+1)*10}\", leave=False):\n",
    "      for step, batch in enumerate(loader):\n",
    "        x0 = batch[0].to(device)\n",
    "        n = len(x0)\n",
    "\n",
    "        # Picking some noise for each of the images in the batch, a timestep and the respective alpha_bars\n",
    "        eta = torch.randn_like(x0).to(device)\n",
    "        t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "\n",
    "        noisy_imgs = ddpm(x0, t, eta)\n",
    "        eta_theta = ddpm.backward(noisy_imgs, t.reshape(n, -1))\n",
    "\n",
    "        # Simple Loss\n",
    "        loss = mse(eta_theta,eta)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epoch_loss += loss.item() * len(x0)/len(loader.dataset)\n",
    "    if display and epoch % 2 == 0:\n",
    "      show_images(sampling(ddpm, device=device), f\"Images generated at epoch {epoch*10+10}\")\n",
    "\n",
    "    log_string = f\"Loss at epoch {epoch + 1}: {epoch_loss:.3f}\"\n",
    "\n",
    "    print(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, min_beta, max_beta = 1000, 10 ** -4, 0.02  # Originally used by the authors\n",
    "ddpm = DDPM(UNet(n_steps), n_steps=n_steps, min_b=min_beta, max_b=max_beta, device=device)\n",
    "optim=AdamW(ddpm.parameters(),lr=2e-5,eps=1e-8)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "training_loop(ddpm, loader,optim, device, n_epochs=1000,  display=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
